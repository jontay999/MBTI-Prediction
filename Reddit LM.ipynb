{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn import svm\n",
    "\n",
    "import sys\n",
    "# add parent directory to the path as well, if running from the finetune folder\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.insert(0, parent_dir)\n",
    "sys.path.insert(0, os.getcwd())\n",
    "\n",
    "import utils.gen_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(inp_dir, dataset, embed, embed_mode, mode, layer):\n",
    "    \"\"\"Read data from pkl file and prepare for training.\"\"\"\n",
    "    file = open(\n",
    "        inp_dir + dataset + \"-\" + embed + \"-\" + embed_mode + \"-\" + mode + \".pkl\", \"rb\"\n",
    "    )\n",
    "    data = pickle.load(file)\n",
    "    author_ids, data_x, data_y = list(zip(*data))\n",
    "    file.close()\n",
    "\n",
    "    # alphaW is responsible for which BERT layer embedding we will be using\n",
    "    if layer == \"all\":\n",
    "        alphaW = np.full([n_hl], 1 / n_hl)\n",
    "\n",
    "    else:\n",
    "        alphaW = np.zeros([n_hl])\n",
    "        alphaW[int(layer) - 1] = 1\n",
    "\n",
    "    # just changing the way data is stored (tuples of minibatches) and\n",
    "    # getting the output for the required layer of BERT using alphaW\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    n_batches = len(data_y)\n",
    "    for ii in range(n_batches):\n",
    "        inputs.extend(np.einsum(\"k,kij->ij\", alphaW, data_x[ii]))\n",
    "        targets.extend(data_y[ii])\n",
    "\n",
    "    inputs = np.array(inputs)\n",
    "    full_targets = np.array(targets)\n",
    "\n",
    "    return inputs, full_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVMclassification(X_train, X_test, y_train, y_test, file_name):\n",
    "    \"\"\"Run classification algorithm (SVM)\"\"\"\n",
    "    \"\"\" (commented lines can save SVM model) \"\"\"\n",
    "\n",
    "    classifier = svm.SVC(gamma=\"scale\")\n",
    "    classifier.fit(X_train, y_train)\n",
    "    # model_name = file_name + '.joblib'\n",
    "    # joblib.dump(classifier, model_name)\n",
    "    acc = classifier.score(X_test, y_test)\n",
    "    return acc\n",
    "\n",
    "\n",
    "def SVMtraining(dataset, inputs, full_targets):\n",
    "    \"\"\"Train model for each trait on 10-fold corss-validtion.\"\"\"\n",
    "\n",
    "    trait_labels = [\"E\", \"N\", \"F\", \"J\"]\n",
    "    n_splits = 10\n",
    "    expdata = {}\n",
    "    expdata[\"acc\"], expdata[\"trait\"], expdata[\"fold\"] = [], [], []\n",
    "    print\n",
    "\n",
    "    for trait_idx in range(full_targets.shape[1]):\n",
    "        # convert targets to one-hot encoding\n",
    "        targets = full_targets[:, trait_idx]\n",
    "        n_data = targets.shape[0]\n",
    "\n",
    "        expdata[\"trait\"].extend([trait_labels[trait_idx]] * n_splits)\n",
    "        expdata[\"fold\"].extend(np.arange(1, n_splits + 1))\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=False)\n",
    "        k = -1\n",
    "        for train_index, test_index in skf.split(inputs, targets):\n",
    "            x_train, x_test = inputs[train_index], inputs[test_index]\n",
    "            y_train, y_test = targets[train_index], targets[test_index]\n",
    "\n",
    "            k += 1\n",
    "            acc = SVMclassification(\n",
    "                x_train,\n",
    "                x_test,\n",
    "                y_train,\n",
    "                y_test,\n",
    "                \"SVM-\" + dataset + \"-\" + embed + \"-\" + str(k) + \"_t\" + str(trait_idx),\n",
    "            )\n",
    "            expdata[\"acc\"].append(100 * acc)\n",
    "\n",
    "    df = pd.DataFrame.from_dict(expdata)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLPtraining(dataset, inputs, full_targets):\n",
    "    \"\"\"Train MLP model for each trait on 10-fold corss-validtion.\"\"\"\n",
    "    trait_labels = [\"E\", \"N\", \"F\", \"J\"]\n",
    "    \n",
    "    \n",
    "    n_classes = 2\n",
    "    lr = 3e-4\n",
    "    epochs = 20\n",
    "    batch_size = 2\n",
    "    \n",
    "    \n",
    "    \n",
    "    n_splits = 10\n",
    "    fold_acc = {}\n",
    "    expdata = {}\n",
    "    expdata[\"acc\"], expdata[\"trait\"], expdata[\"fold\"] = [], [], []\n",
    "\n",
    "    for trait_idx in range(full_targets.shape[1]):\n",
    "        # convert targets to one-hot encoding\n",
    "        targets = full_targets[:, trait_idx]\n",
    "        n_data = targets.shape[0]\n",
    "\n",
    "        expdata[\"trait\"].extend([trait_labels[trait_idx]] * n_splits)\n",
    "        expdata[\"fold\"].extend(np.arange(1, n_splits + 1))\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=False)\n",
    "        k = -1\n",
    "        for train_index, test_index in skf.split(inputs, targets):\n",
    "            x_train, x_test = inputs[train_index], inputs[test_index]\n",
    "            y_train, y_test = targets[train_index], targets[test_index]\n",
    "            # converting to one-hot embedding\n",
    "            y_train = tf.keras.utils.to_categorical(y_train, num_classes=n_classes)\n",
    "            y_test = tf.keras.utils.to_categorical(y_test, num_classes=n_classes)\n",
    "            model = tf.keras.models.Sequential()\n",
    "\n",
    "            # define the neural network architecture\n",
    "            model.add(\n",
    "                tf.keras.layers.Dense(50, input_dim=hidden_dim, activation=\"relu\")\n",
    "            )\n",
    "            model.add(tf.keras.layers.Dense(n_classes))\n",
    "\n",
    "            k += 1\n",
    "            model.compile(\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                metrics=[\"mse\", \"accuracy\"],\n",
    "            )\n",
    "\n",
    "            history = model.fit(\n",
    "                x_train,\n",
    "                y_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                validation_data=(x_test, y_test),\n",
    "                verbose=0,\n",
    "            )\n",
    "\n",
    "            expdata[\"acc\"].append(100 * max(history.history[\"val_accuracy\"]))\n",
    "    print(expdata)\n",
    "    df = pd.DataFrame.from_dict(expdata)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reddit : albert-base : all :  : mean\n"
     ]
    }
   ],
   "source": [
    "inp_dir = \"pk1_data/\"\n",
    "dataset = \"reddit\"\n",
    "embed = \"albert-base\"\n",
    "embed_mode = \"mean\"\n",
    "mode = \"\"\n",
    "network = \"SVM\"\n",
    "MODEL_INPUT = \"LM_features\"\n",
    "seed = 1337\n",
    "layer = \"all\"\n",
    "print(\"{} : {} : {} : {} : {}\".format(dataset, embed, layer, mode, embed_mode))\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "if re.search(r\"base\", embed):\n",
    "    n_hl = 12\n",
    "    hidden_dim = 768\n",
    "elif re.search(r\"large\", embed):\n",
    "    n_hl = 24\n",
    "    hidden_dim = 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testSVM():\n",
    "    start = time.time()\n",
    "    inputs, full_targets = get_inputs(inp_dir, dataset, embed, embed_mode, mode, layer)\n",
    "    df = SVMtraining(dataset, inputs, full_targets)\n",
    "    end = time.time()\n",
    "    print(f\"Took: {int(end - start)} seconds\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testMLP():\n",
    "    start = time.time()\n",
    "    inputs, full_targets = get_inputs(inp_dir, dataset, embed, embed_mode, mode, layer)\n",
    "    df = MLPtraining(dataset, inputs, full_targets)\n",
    "    end = time.time()\n",
    "    print(f\"Took: {int(end - start)} seconds\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 5 seconds\n"
     ]
    }
   ],
   "source": [
    "df1 = testSVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': [72.00000286102295, 73.46938848495483, 73.46938848495483, 75.51020383834839, 75.51020383834839, 75.51020383834839, 73.46938848495483, 73.46938848495483, 73.46938848495483, 73.46938848495483, 93.99999976158142, 95.91836929321289, 95.91836929321289, 93.87755393981934, 93.87755393981934, 93.87755393981934, 93.87755393981934, 93.87755393981934, 93.87755393981934, 93.87755393981934, 54.00000214576721, 57.14285969734192, 59.183675050735474, 57.14285969734192, 57.14285969734192, 67.34693646430969, 73.46938848495483, 53.06122303009033, 57.14285969734192, 55.10203838348389, 68.00000071525574, 65.30612111091614, 63.26530575752258, 63.26530575752258, 67.34693646430969, 69.38775777816772, 65.30612111091614, 65.30612111091614, 61.22449040412903, 63.26530575752258], 'trait': ['E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'J', 'J', 'J', 'J', 'J', 'J', 'J', 'J', 'J', 'J'], 'fold': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
      "Took: 132 seconds\n"
     ]
    }
   ],
   "source": [
    "df2 = testMLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trait</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>73.118367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>52.959184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J</th>\n",
       "      <td>61.097959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>94.297959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             acc\n",
       "trait           \n",
       "E      73.118367\n",
       "F      52.959184\n",
       "J      61.097959\n",
       "N      94.297959"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM\n",
    "df1.groupby(['trait']).mean().drop(columns=['fold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trait</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>73.934695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>59.073470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J</th>\n",
       "      <td>65.167347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>94.297962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             acc\n",
       "trait           \n",
       "E      73.934695\n",
       "F      59.073470\n",
       "J      65.167347\n",
       "N      94.297962"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MLP\n",
    "df2.groupby(['trait']).mean().drop(columns=['fold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import pickle\n",
    "import re\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import *\n",
    "\n",
    "import utils.gen_utils as utils\n",
    "from utils.data_utils import MyMapDataset\n",
    "import os\n",
    "from pathlib import Path\n",
    "import utils.dataset_processors as dataset_processors\n",
    "\n",
    "# sys.path.insert(0, os.getcwd())\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    print(\"GPU found (\", torch.cuda.get_device_name(torch.cuda.current_device()), \")\")\n",
    "    torch.cuda.set_device(torch.cuda.current_device())\n",
    "    print(\"num device avail: \", torch.cuda.device_count())\n",
    "\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(\"running on cpu\")\n",
    "\n",
    "\n",
    "def extract_bert_features(input_ids, mode, n_hl):\n",
    "    \"\"\"Extract bert embedding for each input.\"\"\"\n",
    "    tmp = []\n",
    "    bert_output = model(input_ids)\n",
    "    # bert_output[2](this id gives all BERT outputs)[ii+1](which BERT layer)[:,0,:](taking the <CLS> output)\n",
    "\n",
    "    for ii in range(n_hl):\n",
    "        if embed_mode == \"cls\":\n",
    "            tmp.append(bert_output[2][ii + 1][:, 0, :].cpu().numpy())\n",
    "        elif embed_mode == \"mean\":\n",
    "            tmp.append((bert_output[2][ii + 1].cpu().numpy()).mean(axis=1))\n",
    "\n",
    "    hidden_features.append(np.array(tmp))\n",
    "    return hidden_features\n",
    "\n",
    "\n",
    "def get_model(embed):\n",
    "    # * Model          | Tokenizer          | Pretrained weights shortcut\n",
    "    # MODEL=(DistilBertModel, DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "    if embed == \"bert-base\":\n",
    "        n_hl = 12\n",
    "        hidden_dim = 768\n",
    "        MODEL = (BertModel, BertTokenizer, \"bert-base-uncased\")\n",
    "\n",
    "    elif embed == \"bert-large\":\n",
    "        n_hl = 24\n",
    "        hidden_dim = 1024\n",
    "        MODEL = (BertModel, BertTokenizer, \"bert-large-uncased\")\n",
    "\n",
    "    elif embed == \"albert-base\":\n",
    "        n_hl = 12\n",
    "        hidden_dim = 768\n",
    "        MODEL = (AlbertModel, AlbertTokenizer, \"albert-base-v2\")\n",
    "\n",
    "    elif embed == \"albert-large\":\n",
    "        n_hl = 24\n",
    "        hidden_dim = 1024\n",
    "        MODEL = (AlbertModel, AlbertTokenizer, \"albert-large-v2\")\n",
    "\n",
    "    model_class, tokenizer_class, pretrained_weights = MODEL\n",
    "\n",
    "    # load the LM model and tokenizer from the HuggingFace Transformers library\n",
    "    model = model_class.from_pretrained(\n",
    "        pretrained_weights, output_hidden_states=True\n",
    "    )  # output_attentions=False\n",
    "    tokenizer = tokenizer_class.from_pretrained(pretrained_weights, do_lower_case=True)\n",
    "\n",
    "    return model, tokenizer, n_hl, hidden_dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reddit | albert-base | 10 |  | mean\n"
     ]
    }
   ],
   "source": [
    "dataset = 'reddit'\n",
    "token_length = 10\n",
    "batch_size=int(32)\n",
    "embed = 'albert-base'\n",
    "mode = ''\n",
    "op_dir = 'pk1_data'\n",
    "embed_mode = 'mean'\n",
    "print(\n",
    "    \"{} | {} | {} | {} | {}\".format(dataset, embed, token_length, mode, embed_mode)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.decoder.weight', 'predictions.LayerNorm.bias', 'predictions.decoder.bias', 'predictions.dense.weight', 'predictions.bias', 'predictions.LayerNorm.weight', 'predictions.dense.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer, n_hl, hidden_dim = get_model(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: dataset --> reddit\n",
      "E :  0    8881\n",
      "1    2483\n",
      "Name: E, dtype: int64\n",
      "N :  1    10562\n",
      "0      802\n",
      "Name: N, dtype: int64\n",
      "F :  1    6960\n",
      "0    4404\n",
      "Name: F, dtype: int64\n",
      "J :  0    6790\n",
      "1    4574\n",
      "Name: J, dtype: int64\n",
      "Length of df: 11364\n"
     ]
    }
   ],
   "source": [
    "reddit_file = \"data/reddit/5kdata5.csv\"\n",
    "reddit_file = \"data/reddit/4mildata_uncleaned.csv\"\n",
    "start = time.time()\n",
    "map_dataset = MyMapDataset(dataset, tokenizer, token_length, DEVICE, mode, reddit_file)\n",
    "end = time.time()\n",
    "print(f\"Took {int(end-start)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(\n",
    "    dataset=map_dataset,\n",
    "    batch_size=int(batch_size),\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to extract LM embeddings...\n"
     ]
    }
   ],
   "source": [
    "if DEVICE == torch.device(\"cuda\"):\n",
    "    model = model.cuda()\n",
    "    print(\n",
    "        \"\\ngpu mem alloc: \", round(torch.cuda.memory_allocated() * 1e-9, 2), \" GB\"\n",
    "    )\n",
    "\n",
    "print(\"starting to extract LM embeddings...\")\n",
    "\n",
    "hidden_features = []\n",
    "all_targets = []\n",
    "all_author_ids = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Data loader batches:\", len(data_loader))\n",
    "print(\"Batch size:\", batch_size)\n",
    "# get bert embedding for each input\n",
    "for author_ids, input_ids, targets in data_loader:\n",
    "    with torch.no_grad():\n",
    "        all_targets.append(targets.cpu().numpy())\n",
    "        all_author_ids.append(author_ids.cpu().numpy())\n",
    "        extract_bert_features(input_ids, mode, n_hl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting embeddings for reddit dataset: DONE!\n"
     ]
    }
   ],
   "source": [
    "description = \"4mil_uncleaned\"\n",
    "Path(op_dir).mkdir(parents=True, exist_ok=True)\n",
    "pkl_file_name = dataset + \"-\" + embed + \"-\" + embed_mode + \"-\" + description + \".pkl\"\n",
    "\n",
    "file = open(os.path.join(op_dir, pkl_file_name), \"wb\")\n",
    "pickle.dump(zip(all_author_ids, hidden_features, all_targets), file)\n",
    "file.close()\n",
    "\n",
    "# print(timedelta(seconds=int(time.time() - start)), end=' ')\n",
    "print(\"extracting embeddings for {} dataset: DONE!\".format(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
